{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Question Answering on your own data using Azure OpenAI service embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this demo, we use the [Python OpenAI SDK](https://github.com/openai/openai-python) with the [Azure OpenAI service](https://learn.microsoft.com/azure/cognitive-services/openai/overview) to tailor the model to answer questions specifically about the [meals](https://us.pycon.org/2023/onsite/meal-ingredients/) planned at Pycon.\n",
    "\n",
    "> Note: access to the Azure OpenAI service is by approval only. Please see [How do I get access to Azure OpenAI service?](https://learn.microsoft.com/azure/cognitive-services/openai/overview#how-do-i-get-access-to-azure-openai) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and install instructions\n",
    "\n",
    "- Python 3.7+\n",
    "- An Azure OpenAI service resource (or alternatively an OpenAI account)\n",
    "\n",
    "To install the necessary requirements to run the demo, run:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "In this demo, we will configure the library to use the Azure OpenAI service and authenticate using Azure Active Directory (AAD). Alternatively, you can use an API key (see [here](https://github.com/openai/openai-python#microsoft-azure-endpoints))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import azure.identity\n",
    "import dotenv\n",
    "\n",
    "env_file = '/.env'\n",
    "dotenv.load_dotenv(env_file, override=True)\n",
    "\n",
    "openai.api_type = \"azure_ad\"  # using azure endpoints with AAD auth\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]  # the endpoint value\n",
    "openai.api_version = \"2023-03-15-preview\"  # API version, subject to change\n",
    "\n",
    "credential = azure.identity.DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "openai.api_key = token.token  # set the key to the value of the AccessToken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We start by scraping the meal table from the Pycon webpage and converting it into a Dataframe.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read the table from the Pycon meal webpage\n",
    "html = pd.read_html('https://us.pycon.org/2023/onsite/meal-ingredients/')\n",
    "df = html[0]\n",
    "\n",
    "# remove all the empty rows at the bottom\n",
    "df = df.dropna(how='all')\n",
    "df = df.reset_index()\n",
    "\n",
    "# fill in empty cells and group ingredients that fall to second row\n",
    "df['OPTION'].ffill(inplace=True)\n",
    "df['MENU ITEM'].ffill(inplace=True)\n",
    "df['MEAL'].ffill(inplace=True)\n",
    "df = df.dropna(how='any')\n",
    "df = (df.groupby(df['MENU ITEM'].ne(df['MENU ITEM'].shift()).cumsum(), as_index=False)\n",
    "   .agg({'OPTION':'first', 'MEAL': 'first', 'MENU ITEM': \"first\", 'INGREDIENTS': ' '.join})\n",
    "  )\n",
    "\n",
    "# group the row text together under a new text column\n",
    "df[\"text\"] = df.apply(lambda x: f\"{x['OPTION']}, {x['MEAL']}, {x['MENU ITEM']}, {x['INGREDIENTS']}\", axis=1)\n",
    "df.to_csv('data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The text is tokenized using `tiktoken` and the number of tokens per text chunk is saved to the Dataframe.\"\"\"\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize the text and save the number of tokens to a new column\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"An embedding is generated for each text chunk. API calls are subject to rate limits so we use backoff library (as an example) to implement exponential backoff.\"\"\"\n",
    "\n",
    "import openai\n",
    "import backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings(x):\n",
    "    return openai.Embedding.create(input=x, engine='text-embedding-ada-002-2')['data'][0]['embedding']\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: get_embeddings(x))\n",
    "df.to_csv('embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPTION</th>\n",
       "      <th>MEAL</th>\n",
       "      <th>MENU ITEM</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>Wednesday Tutorial Lunch</td>\n",
       "      <td>Greek Chicken Power Bowl</td>\n",
       "      <td>Grilled Chicken, Mixed Greens, Cucumber, Tomat...</td>\n",
       "      <td>MEAT, Wednesday Tutorial Lunch, Greek Chicken ...</td>\n",
       "      <td>42</td>\n",
       "      <td>[-0.011288567446172237, -0.014967902563512325,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>Thursday Tutorial Lunch</td>\n",
       "      <td>Beef Stir Fry</td>\n",
       "      <td>Beef, Stir Fried Vegetables, Rice w/Peas &amp; Car...</td>\n",
       "      <td>MEAT, Thursday Tutorial Lunch, Beef Stir Fry, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.004255026578903198, -0.02019380033016205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>Friday Conference Breakfast</td>\n",
       "      <td>Turkey Sausage &amp; Egg Burrito</td>\n",
       "      <td>Turkey Sausage, Egg, Cheese, Flour Tortilla Wrap</td>\n",
       "      <td>MEAT, Friday Conference Breakfast, Turkey Saus...</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.015813421458005905, -0.015404226258397102,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>Friday Conference Lunch</td>\n",
       "      <td>Grilled Chicken Pasta Bowl</td>\n",
       "      <td>Grilled Chicken, Pasta, Broccoli, Alfredo Sauce</td>\n",
       "      <td>MEAT, Friday Conference Lunch, Grilled Chicken...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.00466617988422513, -0.018455589190125465, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>Saturday Conference Breakfast</td>\n",
       "      <td>Bacon &amp; Egg English Muffin</td>\n",
       "      <td>Bacon, Egg, Cheese, English Muffin</td>\n",
       "      <td>MEAT, Saturday Conference Breakfast, Bacon &amp; E...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.006820477079600096, -0.014287382364273071,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OPTION                           MEAL                     MENU ITEM   \n",
       "0   MEAT       Wednesday Tutorial Lunch      Greek Chicken Power Bowl  \\\n",
       "1   MEAT        Thursday Tutorial Lunch                 Beef Stir Fry   \n",
       "2   MEAT    Friday Conference Breakfast  Turkey Sausage & Egg Burrito   \n",
       "3   MEAT        Friday Conference Lunch    Grilled Chicken Pasta Bowl   \n",
       "4   MEAT  Saturday Conference Breakfast    Bacon & Egg English Muffin   \n",
       "\n",
       "                                         INGREDIENTS   \n",
       "0  Grilled Chicken, Mixed Greens, Cucumber, Tomat...  \\\n",
       "1  Beef, Stir Fried Vegetables, Rice w/Peas & Car...   \n",
       "2   Turkey Sausage, Egg, Cheese, Flour Tortilla Wrap   \n",
       "3    Grilled Chicken, Pasta, Broccoli, Alfredo Sauce   \n",
       "4                 Bacon, Egg, Cheese, English Muffin   \n",
       "\n",
       "                                                text  n_tokens   \n",
       "0  MEAT, Wednesday Tutorial Lunch, Greek Chicken ...        42  \\\n",
       "1  MEAT, Thursday Tutorial Lunch, Beef Stir Fry, ...        34   \n",
       "2  MEAT, Friday Conference Breakfast, Turkey Saus...        29   \n",
       "3  MEAT, Friday Conference Lunch, Grilled Chicken...        25   \n",
       "4  MEAT, Saturday Conference Breakfast, Bacon & E...        25   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.011288567446172237, -0.014967902563512325,...  \n",
       "1  [-0.004255026578903198, -0.02019380033016205, ...  \n",
       "2  [-0.015813421458005905, -0.015404226258397102,...  \n",
       "3  [-0.00466617988422513, -0.018455589190125465, ...  \n",
       "4  [-0.006820477079600096, -0.014287382364273071,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The embeddings are loaded into a numpy array and we can visualize the data.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df=pd.read_csv('embeddings.csv', index_col=0)\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The user can ask a question, and an embedding is created for the question. A text similarity search is performed that finds the text chunk from the given context (our meal data) that is most similar to the question using cosine similarity.\n",
    "The generative model is prompted with the question and the relevant text chunks as context. It will answer the question if the answer is found in the context.\"\"\"\n",
    "\n",
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"gpt-35-turbo\",\n",
    "    question=\"what is for lunch on wednesday?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Answer the question in your own words based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Context: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages=messages,\n",
    "        engine=model,\n",
    "    )\n",
    "    answer = response['choices'][0]['message']['content'].strip()\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You should avoid the Vegan Power Bowl served on Wednesday Tutorial Lunch as it contains butternut squash.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"I hate butternut squash. What meals should I avoid?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7085049d7697233156603379ebbaf7cb22b7d69a2740f7ef1ba00723efa02d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Question Answering on your own data using Azure OpenAI service embeddings + Python SDK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this demo, we use the [Python OpenAI SDK](https://github.com/openai/openai-python) with the [Azure OpenAI service](https://learn.microsoft.com/azure/cognitive-services/openai/overview) to tailor the model to answer questions specifically about the [meals](https://us.pycon.org/2023/onsite/meal-ingredients/) planned at Pycon.\n",
    "\n",
    "> Note: access to the Azure OpenAI service is by approval only. Please see [How do I get access to Azure OpenAI service?](https://learn.microsoft.com/azure/cognitive-services/openai/overview#how-do-i-get-access-to-azure-openai) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and install instructions\n",
    "\n",
    "- Python 3.7+\n",
    "- An Azure OpenAI service resource (or alternatively an OpenAI account)\n",
    "\n",
    "To install the necessary requirements to run the demo, run:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "In this demo, we will configure the library to use the Azure OpenAI service and authenticate using Azure Active Directory (AAD). Alternatively, you can use an API key (see [here](https://github.com/openai/openai-python#microsoft-azure-endpoints))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import azure.identity\n",
    "\n",
    "openai.api_type = \"azure_ad\"  # using azure endpoints with AAD auth\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "\n",
    "credential = azure.identity.DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "openai.api_key = token.token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We start by scraping the meal table from the Pycon webpage and converting it into a Dataframe.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read the table from the Pycon meal webpage\n",
    "html = pd.read_html('https://us.pycon.org/2023/onsite/meal-ingredients/')\n",
    "df = html[0]\n",
    "\n",
    "# remove all the empty rows at the bottom\n",
    "df = df.dropna(how='all')\n",
    "df = df.reset_index()\n",
    "\n",
    "# fill in empty cells and group ingredients that fall to second row\n",
    "df['OPTION'].ffill(inplace=True)\n",
    "df['MENU ITEM'].ffill(inplace=True)\n",
    "df['MEAL'].ffill(inplace=True)\n",
    "df = df.dropna(how='any')\n",
    "df = (df.groupby(df['MENU ITEM'].ne(df['MENU ITEM'].shift()).cumsum(), as_index=False)\n",
    "   .agg({'OPTION':'first', 'MEAL': 'first', 'MENU ITEM': \"first\", 'INGREDIENTS': ' '.join})\n",
    "  )\n",
    "\n",
    "# group the row text together under a new text column\n",
    "df[\"text\"] = df.apply(lambda x: f\"{x['OPTION']}, {x['MEAL']}, {x['MENU ITEM']}, {x['INGREDIENTS']}\", axis=1)\n",
    "df.to_csv('data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"4/19/23 note: The meal ingredients webpage changed structure so we need to load the previous data from the csv into a dataframe\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The text is tokenized using `tiktoken` and the number of tokens per text chunk is saved to the Dataframe.\"\"\"\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize the text and save the number of tokens to a new column\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OPTION</th>\n",
       "      <th>MEAL</th>\n",
       "      <th>MENU ITEM</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Wednesday Tutorial Lunch</td>\n",
       "      <td>Greek Chicken Power Bowl</td>\n",
       "      <td>Grilled Chicken, Mixed Greens, Cucumber, Tomat...</td>\n",
       "      <td>MEAT, Wednesday Tutorial Lunch, Greek Chicken ...</td>\n",
       "      <td>42</td>\n",
       "      <td>[-0.011288567446172237, -0.014967902563512325,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Thursday Tutorial Lunch</td>\n",
       "      <td>Beef Stir Fry</td>\n",
       "      <td>Beef, Stir Fried Vegetables, Rice w/Peas &amp; Car...</td>\n",
       "      <td>MEAT, Thursday Tutorial Lunch, Beef Stir Fry, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.004255026578903198, -0.02019380033016205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Friday Conference Breakfast</td>\n",
       "      <td>Turkey Sausage &amp; Egg Burrito</td>\n",
       "      <td>Turkey Sausage, Egg, Cheese, Flour Tortilla Wrap</td>\n",
       "      <td>MEAT, Friday Conference Breakfast, Turkey Saus...</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.015813421458005905, -0.015404226258397102,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Friday Conference Lunch</td>\n",
       "      <td>Grilled Chicken Pasta Bowl</td>\n",
       "      <td>Grilled Chicken, Pasta, Broccoli, Alfredo Sauce</td>\n",
       "      <td>MEAT, Friday Conference Lunch, Grilled Chicken...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.00466617988422513, -0.018455589190125465, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Saturday Conference Breakfast</td>\n",
       "      <td>Bacon &amp; Egg English Muffin</td>\n",
       "      <td>Bacon, Egg, Cheese, English Muffin</td>\n",
       "      <td>MEAT, Saturday Conference Breakfast, Bacon &amp; E...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.006820477079600096, -0.014287382364273071,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 OPTION                           MEAL   \n",
       "0           0   MEAT       Wednesday Tutorial Lunch  \\\n",
       "1           1   MEAT        Thursday Tutorial Lunch   \n",
       "2           2   MEAT    Friday Conference Breakfast   \n",
       "3           3   MEAT        Friday Conference Lunch   \n",
       "4           4   MEAT  Saturday Conference Breakfast   \n",
       "\n",
       "                      MENU ITEM   \n",
       "0      Greek Chicken Power Bowl  \\\n",
       "1                 Beef Stir Fry   \n",
       "2  Turkey Sausage & Egg Burrito   \n",
       "3    Grilled Chicken Pasta Bowl   \n",
       "4    Bacon & Egg English Muffin   \n",
       "\n",
       "                                         INGREDIENTS   \n",
       "0  Grilled Chicken, Mixed Greens, Cucumber, Tomat...  \\\n",
       "1  Beef, Stir Fried Vegetables, Rice w/Peas & Car...   \n",
       "2   Turkey Sausage, Egg, Cheese, Flour Tortilla Wrap   \n",
       "3    Grilled Chicken, Pasta, Broccoli, Alfredo Sauce   \n",
       "4                 Bacon, Egg, Cheese, English Muffin   \n",
       "\n",
       "                                                text  n_tokens   \n",
       "0  MEAT, Wednesday Tutorial Lunch, Greek Chicken ...        42  \\\n",
       "1  MEAT, Thursday Tutorial Lunch, Beef Stir Fry, ...        34   \n",
       "2  MEAT, Friday Conference Breakfast, Turkey Saus...        29   \n",
       "3  MEAT, Friday Conference Lunch, Grilled Chicken...        25   \n",
       "4  MEAT, Saturday Conference Breakfast, Bacon & E...        25   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.011288567446172237, -0.014967902563512325,...  \n",
       "1  [-0.004255026578903198, -0.02019380033016205, ...  \n",
       "2  [-0.015813421458005905, -0.015404226258397102,...  \n",
       "3  [-0.00466617988422513, -0.018455589190125465, ...  \n",
       "4  [-0.006820477079600096, -0.014287382364273071,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"An embedding is generated for each text chunk. API calls are subject to rate limits so we use backoff library (as an example) to implement exponential backoff.\"\"\"\n",
    "\n",
    "import openai\n",
    "import backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings(x):\n",
    "    return openai.Embedding.create(input=x, deployment_id='text-embedding-ada-002-2')['data'][0]['embedding']\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: get_embeddings(x))\n",
    "df.to_csv('embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create context to give to the model to use when answering the question.\n",
    "\n",
    "0. Ask a question\n",
    "1. Generate embedding for the question\n",
    "2. Find the text chunk from the given context (our meal data) that is most similar to the question using cosine similarity\n",
    "3. Return that as the context for which the model should use to answer the question\n",
    "\n",
    "Input:\n",
    "> Context text\n",
    "> Question\n",
    "\"\"\"\n",
    "\n",
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "def create_context(\n",
    "    question, df, max_len\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, deployment_id='text-embedding-ada-002-2')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The generative model is prompted with the question and the relevant text chunks as context. It will answer the question if the answer is found in the context.\"\"\"\n",
    "\n",
    "def ask_question(\n",
    "    df,\n",
    "    model=\"gpt-4\",\n",
    "    question=\"what is for lunch on wednesday?\",\n",
    "    max_len=1800,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Answer the question in your own words based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Context: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages=messages,\n",
    "        deployment_id=model,\n",
    "    )\n",
    "    answer = response['choices'][0]['message']['content'].strip()\n",
    "    return answer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You should avoid the Vegan Power Bowl, which contains Butternut Squash, during Wednesday Tutorial Lunch.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(df, question=\"I hate butternut squash. What meals should I avoid?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7085049d7697233156603379ebbaf7cb22b7d69a2740f7ef1ba00723efa02d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
